{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HSMA 6 Certification Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "### SECTION A - Core Python\n",
    "You should complete **all** of the tasks in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task A1** \n",
    "\n",
    "Study the following code.  \n",
    "\n",
    "Add to the code cell some conditional logic that checks whether the randomly generated variable `age` is already in the list of ages.  \n",
    "\n",
    "If it is, a message should be printed to the user confirming the age and the fact that it is in the list.  \n",
    "\n",
    "If it is not, the age should be added to the list, and a message printed confirming the age that has been added to the list. \n",
    "\n",
    "*(5 marks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "list_of_ages = [46, 21, 23, 81, 52]\n",
    "\n",
    "age = random.randint(1,100)\n",
    "\n",
    "# SOLUTION\n",
    "if age in list_of_ages:\n",
    "    print (f\"Age {age} is one of the ages!\")\n",
    "else:\n",
    "    list_of_ages.append(age)\n",
    "    print (f\"Age {age} added to the list\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task A2** \n",
    "\n",
    "Add a function to the following code that takes as its input a list of numbers, and return how many numbers in the list are precisely divisible by 3.  \n",
    "\n",
    "Once you've written the function definition, call the function on the randomly generated list of ages, and print a message confirming how many ages in the list are divisible by 3. \n",
    "\n",
    "*(10 marks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "list_of_ages = [random.randint(1,100) for x in range(100)]\n",
    "\n",
    "# SOLUTION\n",
    "def find_numbers_divisible_by_three(list_of_nums):\n",
    "    count_div_by_3 = 0\n",
    "\n",
    "    for num in list_of_nums:\n",
    "        if num % 3 == 0:\n",
    "            count_div_by_3 += 1\n",
    "\n",
    "    return count_div_by_3\n",
    "\n",
    "total_div_by_3 = find_numbers_divisible_by_three(list_of_ages)\n",
    "print (f\"There are {total_div_by_3} ages divisible by 3 in the list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task A3** \n",
    "\n",
    "In the following code cell, write a class definiton for a class representing a jukebox.  The jukebox should have two attributes - an era of music that it represents (stored as a string) and a dictionary which stores numbers against song titles.  The era is specified when the Jukebox is created, and the jukebox begins with no songs in its dictionary.  The jukebox class should also have three methods :\n",
    "\n",
    "- one to add a song, given a song title and a song number\n",
    "- one to remove a song, given a song number\n",
    "- one to display the current songs on the jukebox, as well as a message to the user telling them what era of songs the jukebox has\n",
    "\n",
    "Once you've written the class definition, you should create a new jukebox named `eighties_jukebox` (Note - do NOT name it `80s_jukebox` or you will run into problems).  Add three songs to the jukebox :\n",
    "- Song 1 : The One and Only\n",
    "- Song 2 : Everywhere\n",
    "- Song 3 : West End Girls\n",
    "\n",
    "Then display the current songs on the jukebox.\n",
    "\n",
    "Then, remove song 2, and display the current songs again. \n",
    "\n",
    "*(15 marks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "class Jukebox:\n",
    "    def __init__(self, specified_era):\n",
    "        self.era = specified_era\n",
    "\n",
    "        self.jukebox_dictionary = {}\n",
    "\n",
    "    def add_song(self, song_title, song_number):\n",
    "        self.jukebox_dictionary[song_number] = song_title\n",
    "\n",
    "    def remove_song(self, song_number):\n",
    "        del self.jukebox_dictionary[song_number]\n",
    "\n",
    "    def display_current_songs(self):\n",
    "        print (f\"This is a jukebox of {self.era} songs\")\n",
    "        print (self.jukebox_dictionary)\n",
    "\n",
    "eighties_jukebox = Jukebox(\"80s\")\n",
    "\n",
    "eighties_jukebox.add_song(\"The One and Only\", 1)\n",
    "eighties_jukebox.add_song(\"Everywhere\", 2)\n",
    "eighties_jukebox.add_song(\"West End Girls\", 3)\n",
    "\n",
    "eighties_jukebox.display_current_songs()\n",
    "\n",
    "eighties_jukebox.remove_song(2)\n",
    "\n",
    "eighties_jukebox.display_current_songs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2\n",
    "\n",
    "You should now select just **TWO** of the following sections to answer.  \n",
    "\n",
    "Do not answer more than two, as only two will be marked.  \n",
    "\n",
    "It is also recommended that if you change your mind about tackling a particular task and choose another instead, you should delete any code you began in the task you rejected before submitting your notebook.  \n",
    "\n",
    "All tasks in the following sections are worth identical marks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION B - Discrete Event Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task B** \n",
    "\n",
    "*Use the **des** environment for this question*\n",
    "\n",
    "Study the following simplified SimPy model of Dan's Diner.  In Dan's Diner, diners arrive, wait for a server to order their food, then wait for a table to sit and eat their food before leaving.  Your task is to complete the missing code as indicated below.  Specifically :\n",
    "\n",
    "- write the code for the generator function that generates new diner arrivals (`generator_diner_arrivals`).  You should use the `diner_counter` to provide each diner with a unique ID.  You should assume that the inter-arrival times of diners are exponentially distributed.\n",
    "- write the code for the generator function representing an individual diner's journey through Dan's Diner (`attend_diner`).  You should assume that the times that diners spend ordering and eating are exponentionally distributed.  You should calculate the time each diner spends in each queue and record this against their attributes (`q_time_order` and `q_time_table`).  HOWEVER, you do NOT need to record the data anywhere else, such as in a DataFrame.\n",
    "\n",
    "You should note that this is a simplified model that only runs for one run and does not record results across the run - the only recorded metrics are the queuing times stored by each diner.  If you have written the code correctly, the model should run and display messages such as \"Diner 11 waited 3 mins to be served and 10 mins for a table\" \n",
    "\n",
    "*(20 marks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "import random\n",
    "\n",
    "class g:\n",
    "    diner_inter = 1\n",
    "    mean_order_time = 2\n",
    "    mean_eating_time = 15\n",
    "    number_of_servers = 2\n",
    "    number_of_tables = 5\n",
    "    sim_duration = 120\n",
    "\n",
    "class Diner:\n",
    "    def __init__(self, d_id):\n",
    "        self.id = d_id\n",
    "        self.q_time_order = 0\n",
    "        self.q_time_table = 0\n",
    "\n",
    "class Dans_Diner_Model:\n",
    "    def __init__(self):\n",
    "        self.env = simpy.Environment()\n",
    "\n",
    "        self.diner_counter = 0\n",
    "\n",
    "        self.server = simpy.Resource(self.env, capacity=g.number_of_servers)\n",
    "        self.table = simpy.Resource(self.env, capacity=g.number_of_tables)\n",
    "\n",
    "    def generator_diner_arrivals(self):\n",
    "        # SOLUTION - INSERT CODE HERE\n",
    "        while True:\n",
    "            self.diner_counter += 1\n",
    "            d = Diner(self.diner_counter)\n",
    "            self.env.process(self.attend_diner(d))\n",
    "            sampled_inter = random.expovariate(1.0 / g.diner_inter)\n",
    "            yield self.env.timeout(sampled_inter)\n",
    "\n",
    "    def attend_diner(self, diner):\n",
    "        # SOLUTION - INSERT CODE HERE\n",
    "        start_q_order = self.env.now\n",
    "\n",
    "        with self.server.request() as req:\n",
    "            yield req\n",
    "\n",
    "            end_q_order = self.env.now\n",
    "\n",
    "            diner.q_time_order = end_q_order - start_q_order\n",
    "\n",
    "            sampled_order_time = random.expovariate(1.0 / g.mean_order_time)\n",
    "\n",
    "            yield self.env.timeout(sampled_order_time)\n",
    "\n",
    "        start_q_table = self.env.now\n",
    "\n",
    "        with self.table.request() as req:\n",
    "            yield req\n",
    "\n",
    "            end_q_table = self.env.now\n",
    "\n",
    "            diner.q_time_table = end_q_table - start_q_table\n",
    "\n",
    "            sampled_eating_time = random.expovariate(1.0 / g.mean_eating_time)\n",
    "\n",
    "            yield self.env.timeout(sampled_eating_time)\n",
    "\n",
    "        # END OF SOLUTION - PROVIDE BELOW CODE\n",
    "        print (f\"Diner {diner.id} waited {diner.q_time_order:.0f} mins to be\",\n",
    "               f\"served and {diner.q_time_table:.0f} mins for a table\")\n",
    "\n",
    "    def run(self):\n",
    "        self.env.process(self.generator_diner_arrivals())\n",
    "        self.env.run(until=g.sim_duration)\n",
    "\n",
    "my_diner_model = Dans_Diner_Model()\n",
    "my_diner_model.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION C - GEOGRAPHIC MODELLING AND VISUALISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task C** \n",
    "\n",
    "*Use the **geographic** environment for this question*\n",
    "\n",
    "You have been provided with \n",
    "- the name, latitude and longitude of the 20 biggest theme parks in the UK *(theme_park_locations_gdf)*\n",
    "- the travel times (by car, in minutes) to these theme parks from a range of Local Authorities in England *(travel_times_df)*\n",
    "- a geographic data file containing the boundaries of these local authorities *(local_authority_boundaries_gdf)*\n",
    "\n",
    "In the code cell below, create a static (non-interactive) map showing the travel time from each Local Authority to its **nearest** theme park. \n",
    "\n",
    "You will need to perform the following steps to create this map. \n",
    "\n",
    "1. Create an extra column in the dataframe *travel_times_df* calculating the nearest theme park for each Local Authority.\n",
    "\n",
    "2. Join *local_authority_boundaries_gdf* and *travel_times_df*. \n",
    "    - Note that they both contain the column \"LAD21NM\", though it is the *index* of *local_authority_boundaries_gdf*. You may need to use the command *.reset_index()* on *local_authority_boundaries_gdf* during this step. \n",
    "\n",
    "3. Plot the travel times.\n",
    "    - The colour of each Local Authority should reflect the travel time to the location. \n",
    "    - Your map should include\n",
    "        - a legend showing what the colour indicates\n",
    "        - a title\n",
    "\n",
    "4. Finally, plot the location of the theme parks *(theme_park_locations_gdf)* as points on the **same map**. Use 'blue' as the colour for the points.  \n",
    "\n",
    "Note that all geographic data in this task makes use of latitude and longitude. If you are specifying a CRS in your code, use **EPSG:4326**. \n",
    "\n",
    "*(20 marks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "travel_times_df = pd.read_csv(\"data/la_to_theme_park_travel.csv\", index_col=\"LAD21NM\")\n",
    "theme_park_locations_gdf = geopandas.read_file(\"data/Theme_Parks_England.geojson\")\n",
    "local_authority_boundaries_gdf = geopandas.read_file(\"data/local_authority_boundaries.geojson\")\n",
    "\n",
    "# SOLUTION\n",
    "\n",
    "travel_times_df['shortest'] = travel_times_df.min(axis=1)\n",
    "\n",
    "nearest_theme_park_gdf = pd.merge(\n",
    "    local_authority_boundaries_gdf,\n",
    "    travel_times_df.reset_index(),\n",
    "    left_on=\"LAD21NM\",\n",
    "    right_on=\"LAD21NM\",\n",
    "    how=\"right\"\n",
    ")\n",
    "\n",
    "ax = nearest_theme_park_gdf.plot(\n",
    "    column='shortest',\n",
    "    legend=True\n",
    "    )\n",
    "\n",
    "ax.set_title(\"Travel Time to Theme Parks\")\n",
    "\n",
    "theme_park_locations_gdf.plot(ax=ax, color=\"blue\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION D - DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task D**\n",
    "\n",
    "*Use the **tf_hsma** environment for this question*\n",
    "\n",
    "In the code cell below, using the Keras API build a Sequential Neural Network comprised of : \n",
    "- A densely connected layer with 16 hidden neurons, an input dimension of 30 features and a rectified linear unit activation function on each neuron\n",
    "- A dropout layer with a dropout rate of 40%\n",
    "- Another pair of layers exactly as described above\n",
    "- An output layer consisting of one densely connected neuron with a sigmoid activation function\n",
    "\n",
    "Once you have built the model, compile it with a binary crossentropy loss function, an Adam optimizer and a metric of accuracy to monitor.  Then print a summary of the network's structure.\n",
    "\n",
    "Note - you do not need to read in, use or manipulate any data for this task, nor do you need to train the model.  Just build the structure of the network, compile it and show a summary of its structure. \n",
    "\n",
    "\n",
    "*(20 marks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# SOLUTION\n",
    "net = Sequential()\n",
    "\n",
    "net.add(Dense(16,input_dim=30, activation='relu'))\n",
    "net.add(Dropout(0.4))\n",
    "net.add(Dense(16,input_dim=30, activation='relu'))\n",
    "net.add(Dropout(0.4))\n",
    "net.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "net.compile(loss='binary_crossentropy',\n",
    "            optimizer='Adam',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION E - TREE-BASED MACHINE LEARNING MODELS\n",
    "\n",
    "**Task E** \n",
    "\n",
    "*Use the **ml_sammi** environment for this question*\n",
    "\n",
    "Dan has been keeping a record of the different cat treats Prince likes, and the details of those treats such as their protein content and the main flavours. This is stored in `prince_treats.csv`.\n",
    "\n",
    "Train an XGBoost model on the provided dataset. \n",
    "\n",
    "- Split the data into X (your features) and y (your target - the column `prince_likes`, with 1 indicating that Prince liked the treat and 0 indicating that he didn't). \n",
    "\n",
    "- Split these into training and testing sets.\n",
    "    - Use 70% of the dataset for training, and 30% for testing. \n",
    "    - Make sure you set a random seed so that your results are reproducible.\n",
    "\n",
    "- Initialise an XGBoost model and train it on the relevant datasets. \n",
    "\n",
    "- Use your model to create predictions, then \n",
    "    - For your testing data, calculate the accuracy and 'macro' f1 score, and print these values to three decimal places.\n",
    "    - Create an AUC plot using your testing dataset. \n",
    "    - Create a confusion matrix using your testing dataset. (hint: if this doesn't display in the notebook, try adding '.plot()' to the end of your code)\n",
    "\n",
    "*(20 marks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score, f1_score, \\\n",
    "                            confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "treats_df = pd.read_csv(\"data/prince_treats.csv\")\n",
    "\n",
    "#SOLUTION\n",
    "X = treats_df.drop('prince_likes', axis=1) # X = all 'data' except the 'died' column\n",
    "y = treats_df['prince_likes'] # y = 'died' column from 'data'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "model = XGBClassifier(random_state=42)\n",
    "model = model.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test = f1_score(y_test, y_pred_test, average='macro')\n",
    "\n",
    "print (f'Accuracy of predicting test data = {accuracy_test:.3f}')\n",
    "print (f'F1 score = {precision_test :.3f}')\n",
    "\n",
    "RocCurveDisplay.from_estimator(\n",
    "    model, X_test, y_test\n",
    ")\n",
    "\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred_test\n",
    "        ),\n",
    "        display_labels=[\"Doesn't Like\", \"Likes\"]\n",
    ").plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION F - NATURAL LANGUAGE PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task F** \n",
    "\n",
    "*Use the **nlp_basics** environment for this question.*  **IMPORTANT-You will need to pip install the `requests` library in this environment in order for the code to work, if you have not already done so**\n",
    "\n",
    "The code cell below reads in the sarcastic reviews HSMAs wrote for session 5C of HSMA 6.  Add to this code cell to vectorize the text in each review using a bag of words representation.  Convert the vectorization into a Pandas DataFrame, and then :\n",
    "\n",
    "1. print the vector of numbers representing the second review\n",
    "2. print the frequencies of the word \"world\" across all 10 reviews\n",
    "\n",
    "*(20 marks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "list_of_reviews = []\n",
    "\n",
    "for review_num in range(1,11):\n",
    "    url = (\"https://raw.githubusercontent.com/hsma-programme/\"\n",
    "           \"h6_5c_sentiment_analysis/main/5c_sentiment_analysis/\"\n",
    "           f\"sarcastic_reviews/sarcastic_{review_num}.txt\")\n",
    "    response = requests.get(url)\n",
    "    list_of_reviews.append(response.text)\n",
    "\n",
    "# SOLUTION\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(list_of_reviews)\n",
    "\n",
    "column_names = vectorizer.get_feature_names_out()\n",
    "bow_df = pd.DataFrame(bag_of_words.toarray(), columns=column_names)\n",
    "\n",
    "print (bow_df.iloc[1].values)\n",
    "\n",
    "selected_word = \"world\"\n",
    "print (bow_df[selected_word])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION G - BEHAVIOURAL MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task G** \n",
    "\n",
    "*Use the **abs** environment for this question*\n",
    "\n",
    "The code below is setting up an Agent Based Simulation of a zombie apocalypse in MESA.  However, there are three methods missing in the `Human` class, which you need to write :\n",
    "1. a `move` method which will move the agent to a *different* cell at random using a Moore neighbourhood\n",
    "2. an `infect` method which will check if there are other agents in the same cell, and if so will turn any non-zombies in the cell into zombies based on the infection probability of the zombie (this method will only called by the step function if the agent is a zombie, so you don't need to check that logic in this method).  If the zombie turns others into zombies, they should also halve the movement frequency of their newly infected victims.\n",
    "3. a `step` method which will first decide whether or not to move the agent (based on their movement probability), and if so begin the move process, and then check whether they are a zombie, and if so begin the infection process.\n",
    "\n",
    "*(20 marks)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mesa\n",
    "\n",
    "from mesa import Agent, Model\n",
    "from mesa.time import RandomActivation\n",
    "from mesa.space import MultiGrid\n",
    "from mesa.datacollection import DataCollector\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "class Human(Agent):\n",
    "    def __init__(self, unique_id, model, initial_zombie_prob, infect_prob,\n",
    "                 movement_prob):\n",
    "        super().__init__(unique_id, model)\n",
    "\n",
    "        self.infect_prob = infect_prob\n",
    "        self.movement_prob = movement_prob\n",
    "\n",
    "        if random.uniform(0, 1) < initial_zombie_prob:\n",
    "            self.is_a_zombie = True\n",
    "            self.movement_prob = self.movement_prob / 2\n",
    "        else:\n",
    "            self.is_a_zombie = False\n",
    "\n",
    "    # SOLUTION\n",
    "    def move(self):\n",
    "        possible_steps = self.model.grid.get_neighborhood(\n",
    "            self.pos, moore=True, include_center=False\n",
    "        )\n",
    "\n",
    "        new_position = random.choice(possible_steps)\n",
    "\n",
    "        self.model.grid.move_agent(self, new_position)\n",
    "\n",
    "    def infect(self):\n",
    "        cellmates = self.model.grid.get_cell_list_contents([self.pos])\n",
    "\n",
    "        if len(cellmates) > 1:\n",
    "            for inhabitant in cellmates:\n",
    "                if inhabitant.is_a_zombie == False:\n",
    "                    if random.uniform(0,1) < self.infect_prob:\n",
    "                        inhabitant.is_a_zombie = True\n",
    "                        inhabitant.movement_prob = inhabitant.movement_prob / 2\n",
    "\n",
    "    def step(self):\n",
    "        if random.uniform(0,1) < self.movement_prob:\n",
    "            self.move()\n",
    "\n",
    "        if self.is_a_zombie == True:\n",
    "            self.infect()\n",
    "    # END OF SOLUTION\n",
    "\n",
    "class Zombie_Model(Model):\n",
    "    def __init__(self, N, width, height, initial_zombie_prob, infect_prob,\n",
    "                 movement_prob):\n",
    "        self.running = True\n",
    "        self.num_agents = N\n",
    "        self.grid = MultiGrid(width, height, True)\n",
    "        self.schedule = RandomActivation(self)\n",
    "\n",
    "        for i in range(self.num_agents):\n",
    "            h = Human(i, self, initial_zombie_prob, infect_prob, movement_prob)\n",
    "            self.schedule.add(h)\n",
    "\n",
    "            self.grid.place_agent(h, (\n",
    "                random.randrange(self.grid.width),\n",
    "                random.randrange(self.grid.height)\n",
    "            ))\n",
    "\n",
    "        self.datacollector = DataCollector(\n",
    "            model_reporters = {\"Total Zombies\":calculate_number_of_zombies},\n",
    "            agent_reporters = {}\n",
    "        )\n",
    "\n",
    "    def step(self):\n",
    "        self.datacollector.collect(self)\n",
    "\n",
    "        self.schedule.step()\n",
    "\n",
    "def calculate_number_of_zombies(model):\n",
    "    zombie_list = [True for human in model.schedule.agents\n",
    "                   if human.is_a_zombie == True]\n",
    "\n",
    "    return len(zombie_list)\n",
    "\n",
    "params = {\"width\":100,\n",
    "          \"height\":100,\n",
    "          \"N\":100,\n",
    "          \"initial_zombie_prob\":0.3,\n",
    "          \"infect_prob\":0.8,\n",
    "          \"movement_prob\":0.7}\n",
    "\n",
    "results = mesa.batch_run(\n",
    "    Zombie_Model,\n",
    "    parameters=params,\n",
    "    iterations=2,\n",
    "    max_steps=200,\n",
    "    number_processes=1,\n",
    "    data_collection_period=-1,\n",
    "    display_progress=True\n",
    ")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print (results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SECTION H - STREAMLIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK H**\n",
    "\n",
    "*Use the **hsma_webdev** environment for this question*\n",
    "\n",
    "*HINT - You may wish to write the app in a separate .py file so you can test it and ensure it runs correctly. Make sure you then paste your code into the code cell below when you are done.*\n",
    "\n",
    "You have been provided with\n",
    "- a *dataframe* of **yearly** counts of a series of animals (animal_df)\n",
    "- a *list* of the individual animals represented in the dataset (animal_list)\n",
    "\n",
    "You have also been provided with two functions\n",
    "- get_fact()\n",
    "- get_image()\n",
    "\n",
    "Write a Streamlit app that\n",
    "\n",
    "- displays an appropriate title\n",
    "- provides the user with a way of selecting an **animal**. You can use any appropriate user input you like to allow them to select this. \n",
    "- provides a 'run' button for the user to press. \n",
    "\n",
    "**All graphs and tables in the app should reflect the selected animal - you will need to filter the dataframes to achieve this**\n",
    "\n",
    "When the user presses the button, two tabs should appear.\n",
    "\n",
    "**In tab 1**\n",
    "*In column 1*\n",
    "- display the fact about the animal using the *get_fact()* function and an appropriate streamlit command\n",
    "\n",
    "*In column 2*\n",
    "- display a picture of the animal using the *get_image()* function and an appropriate streamlit command\n",
    "\n",
    "**In tab 2**\n",
    "\n",
    "- display a line plot of how many of that animal have been counted each year using a plotting library of your choice\n",
    "\n",
    "- display your filtered dataframe using an appropriate streamlit command. *Don't worry if the 'year' column displays a bit strangely!*\n",
    "\n",
    "\n",
    "Finally, When you have completed the above tasks, change the original data import to use **caching**.\n",
    "\n",
    "*(20 marks)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# A dataframe of animals, containing yearly counts, facts and image links\n",
    "animal_df = pd.read_csv(\"data/animal_counts.csv\").sort_values([\"Common_name\", \"Year\"])\n",
    "# A list of the unique animals in the dataset\n",
    "animals = animal_df[\"Common_name\"].unique()\n",
    "\n",
    "def get_fact(dataframe):\n",
    "    return dataframe[\"Fact\"].values[0]\n",
    "\n",
    "def get_image(dataframe):\n",
    "    return dataframe[\"Image\"].values[0]\n",
    "\n",
    "# SOLUTION\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    return pd.read_csv(\"data/animal_counts.csv\").sort_values([\"Common_name\", \"Year\"])\n",
    "\n",
    "animal_df = load_data()\n",
    "animals = animal_df[\"Common_name\"].unique()\n",
    "\n",
    "st.title(\"Animal Numbers Over Time\")\n",
    "\n",
    "selected_animal = st.selectbox(\"Select an Animal\", animals)\n",
    "\n",
    "button_run_pressed = st.button(\"Run\")\n",
    "\n",
    "if button_run_pressed:\n",
    "\n",
    "    # Filtering\n",
    "    single_animal_df = animal_df[animal_df[\"Common_name\"] == selected_animal]\n",
    "\n",
    "    # Setting up tabs\n",
    "    tab1, tab2 = st.tabs([\"Animal Details\", \"Numbers over time\"])\n",
    "\n",
    "    # Displaying the overall data for the animal in tab 1\n",
    "    with tab1:\n",
    "\n",
    "        st.subheader(selected_animal)\n",
    "\n",
    "        col1, col2 = st.columns(2)\n",
    "\n",
    "        with col1:\n",
    "            st.write(get_fact(single_animal_df))\n",
    "\n",
    "        with col2:\n",
    "            st.image(get_image(single_animal_df))\n",
    "\n",
    "    # Displaying the yearly dataframe and table in the final output\n",
    "    with tab2:\n",
    "        st.plotly_chart(\n",
    "                px.line(single_animal_df,\n",
    "                            x=\"Year\",\n",
    "                            y=\"Count\")\n",
    "            )\n",
    "\n",
    "        st.dataframe(single_animal_df[[\"Year\", \"Count\"]], hide_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
